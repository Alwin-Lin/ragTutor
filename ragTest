import streamlit as st
from google.generativeai import GenerativeModel
from sentence_transformers import SentenceTransformer
import numpy as np
from typing import List, Dict, Tuple
import pandas as pd
from sklearn.metrics.pairwise import cosine_similarity

class RAGTutor:
    def __init__(self):
        # Initialize embedding model
        self.embed_model = SentenceTransformer('all-MiniLM-L6-v2')
        
        # Initialize Gemini model
        self.llm = GenerativeModel('gemini-pro')
        
        # Storage for embedded documents
        self.document_embeddings = {}
        self.document_contents = {}
        
    def process_documents(self, 
                         rubric: str,
                         slides: List[str],
                         worksheet: str,
                         examples: Dict[str, List[str]]):
        """Process and embed all course materials"""
        
        # Process rubric
        self.document_contents['rubric'] = rubric
        self.document_embeddings['rubric'] = self.embed_model.encode(rubric)
        
        # Process slides
        self.document_contents['slides'] = slides
        self.document_embeddings['slides'] = self.embed_model.encode(slides)
        
        # Process worksheet
        self.document_contents['worksheet'] = worksheet
        self.document_embeddings['worksheet'] = self.embed_model.encode(worksheet)
        
        # Process examples
        for quality, responses in examples.items():
            key = f'examples_{quality}'
            self.document_contents[key] = responses
            self.document_embeddings[key] = self.embed_model.encode(responses)
    
    def retrieve_relevant_context(self, 
                                query: str, 
                                top_k: int = 3) -> List[str]:
        """Retrieve most relevant content for a given query"""
        query_embedding = self.embed_model.encode(query)
        
        relevant_content = []
        for doc_type, embeddings in self.document_embeddings.items():
            similarities = cosine_similarity([query_embedding], embeddings)[0]
            
            # Get top matches from this document type
            top_indices = np.argsort(similarities)[-top_k:]
            
            for idx in top_indices:
                if isinstance(self.document_contents[doc_type], list):
                    relevant_content.append(self.document_contents[doc_type][idx])
                else:
                    relevant_content.append(self.document_contents[doc_type])
                    
        return relevant_content
    
    def generate_response(self, 
                         student_query: str,
                         student_work: str = None) -> str:
        """Generate tutoring response based on student query and work"""
        
        # Retrieve relevant context
        context = self.retrieve_relevant_context(student_query)
        
        # Construct prompt
        prompt = f"""You are an AI tutor for the course 'Society and the Engineer'.
        
Context from course materials:
{' '.join(context)}

Student query: {student_query}"""

        if student_work:
            prompt += f"\n\nStudent work submitted: {student_work}"
            
            # Add examples of similar quality work if available
            similar_work = self.retrieve_relevant_context(student_work, top_k=2)
            if similar_work:
                prompt += f"\n\nSimilar student work examples: {' '.join(similar_work)}"

        prompt += "\n\nProvide a helpful tutoring response that:"
        prompt += "\n- Addresses the student's specific question"
        prompt += "\n- References relevant course materials"
        prompt += "\n- Provides constructive feedback if student work was submitted"
        prompt += "\n- Encourages critical thinking"
        
        # Generate response using Gemini
        response = self.llm.generate_content(prompt)
        return response.text

# Streamlit UI
def create_tutor_ui():
    st.title("Society and the Engineer - AI Tutor")
    
    # Initialize tutor on first run
    if 'tutor' not in st.session_state:
        st.session_state.tutor = RAGTutor()
        # Load and process documents here
        # st.session_state.tutor.process_documents(...)
    
    # Input areas
    student_query = st.text_area("What's your question?")
    student_work = st.text_area("(Optional) Paste your work here for feedback", height=200)
    
    if st.button("Get Help"):
        if student_query:
            with st.spinner("Generating response..."):
                response = st.session_state.tutor.generate_response(
                    student_query, 
                    student_work if student_work else None
                )
                st.write(response)
        else:
            st.warning("Please enter a question")

if __name__ == "__main__":
    create_tutor_ui()